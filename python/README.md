# cuOP Python API

cuOP Python API æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„CUDAç®—å­å’Œå†…å­˜ç®¡ç†åº“ï¼Œæä¾›JITä¼˜åŒ–ã€æŒä¹…åŒ–ç¼“å­˜å’Œé«˜æ•ˆçš„å†…å­˜ç®¡ç†åŠŸèƒ½ã€‚

## ç‰¹æ€§

- ğŸš€ **é«˜æ€§èƒ½CUDAç®—å­**: æ”¯æŒGEMMã€GEMVã€ReLUã€Softmaxã€MatMulç­‰å¸¸ç”¨ç®—å­
- âš¡ **JITä¼˜åŒ–**: å®æ—¶å†…æ ¸ä¼˜åŒ–ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³é…ç½®
- ğŸ’¾ **æŒä¹…åŒ–ç¼“å­˜**: ç¼–è¯‘ç»“æœæŒä¹…åŒ–ï¼Œæ˜¾è‘—æå‡é‡å¤ä½¿ç”¨æ€§èƒ½
- ğŸ§  **æ™ºèƒ½å†…å­˜ç®¡ç†**: é«˜æ•ˆçš„å†…å­˜æ± å’Œè‡ªåŠ¨å†…å­˜ä¼˜åŒ–
- ğŸ”§ **çµæ´»é…ç½®**: å¯è‡ªå®šä¹‰JITé…ç½®å’Œä¼˜åŒ–å‚æ•°
- ğŸ“Š **æ€§èƒ½åˆ†æ**: å†…ç½®æ€§èƒ½åˆ†æå’ŒåŸºå‡†æµ‹è¯•å·¥å…·
- ğŸ **PythonåŸç”Ÿ**: å®Œå…¨PythonåŒ–çš„APIè®¾è®¡ï¼Œæ˜“äºä½¿ç”¨

## å®‰è£…

### ç³»ç»Ÿè¦æ±‚

- Python 3.7+
- CUDA 11.0+
- NVIDIA GPU (æ”¯æŒCUDA)
- Linux/macOS/Windows

### ä»æºç å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/cuop/cuop.git
cd cuop

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æ„å»ºPythonåŒ…
cd python
pip install -e .
```

### ä¾èµ–å®‰è£…

```bash
pip install numpy pybind11
```

## å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
import cuop
import numpy as np

# åˆ›å»ºå¼ é‡
a = cuop.tensor(np.random.randn(1000, 1000).astype(np.float32))
b = cuop.tensor(np.random.randn(1000, 1000).astype(np.float32))
c = cuop.zeros([1000, 1000])

# ä½¿ç”¨GEMMç®—å­
gemm = cuop.GemmFloat()
gemm.set_weight(b)
gemm.forward(a, c)

# è½¬æ¢ä¸ºnumpyæ•°ç»„
result = c.to_numpy()
```

### JITä¼˜åŒ–ä½¿ç”¨

```python
# åˆ›å»ºJITä¼˜åŒ–çš„ç®—å­
jit_gemm = cuop.JITGemmFloat(gemm)

# å¯ç”¨JITä¼˜åŒ–
jit_gemm.enable_jit(True)

# å¯ç”¨æŒä¹…åŒ–ç¼“å­˜
jit_gemm.enable_persistent_cache(True)
jit_gemm.set_persistent_cache_directory("./jit_cache")

# è®¾ç½®JITé…ç½®
config = cuop.get_default_jit_config()
config.kernel_type = "tiled"
config.tile_size = 32
config.block_size = 256
config.optimization_level = "O2"
config.enable_tensor_core = True

jit_gemm.set_jit_config(config)

# æ‰§è¡Œè®¡ç®—
jit_gemm.forward(a, c)

# è·å–æ€§èƒ½ä¿¡æ¯
profile = jit_gemm.get_performance_profile()
print(f"æ‰§è¡Œæ—¶é—´: {profile.execution_time}ms")
print(f"GFLOPS: {profile.gflops}")
```

### æ‰¹é‡å¤„ç†

```python
# åˆ›å»ºæ‰¹é‡æ•°æ®
batch_size = 100
matrix_size = 256
batch_inputs = []
batch_weights = []

for i in range(batch_size):
    input_data = np.random.randn(matrix_size, matrix_size).astype(np.float32)
    weight_data = np.random.randn(matrix_size, matrix_size).astype(np.float32)
    
    batch_inputs.append(cuop.tensor(input_data))
    batch_weights.append(cuop.tensor(weight_data))

# æ‰¹é‡å¤„ç†
gemm = cuop.GemmFloat()
batch_outputs = [cuop.zeros([matrix_size, matrix_size]) for _ in range(batch_size)]

for i in range(batch_size):
    gemm.set_weight(batch_weights[i])
    gemm.forward(batch_inputs[i], batch_outputs[i])

cuop.synchronize()
```

## APIå‚è€ƒ

### æ ¸å¿ƒç±»

#### Tensor

å¼ é‡ç±»ï¼Œæ”¯æŒå¤šç§æ•°æ®ç±»å‹å’Œå½¢çŠ¶ã€‚

```python
# åˆ›å»ºå¼ é‡
tensor = cuop.TensorFloat([1000, 1000])
tensor = cuop.tensor(np.random.randn(1000, 1000).astype(np.float32))

# å¼ é‡æ“ä½œ
tensor.fill(1.0)           # å¡«å……å€¼
tensor.zero()              # æ¸…é›¶
tensor.copy_from(arr)      # ä»numpyæ•°ç»„å¤åˆ¶
result = tensor.to_numpy() # è½¬æ¢ä¸ºnumpyæ•°ç»„

# å±æ€§
shape = tensor.shape       # è·å–å½¢çŠ¶
size = tensor.size         # è·å–å…ƒç´ æ•°é‡
dtype = tensor.dtype       # è·å–æ•°æ®ç±»å‹
```

#### ç®—å­ç±»

æ”¯æŒå¤šç§CUDAç®—å­ï¼š

- `GemmFloat/GemmDouble`: çŸ©é˜µä¹˜æ³•
- `GemvFloat/GemvDouble`: çŸ©é˜µå‘é‡ä¹˜æ³•
- `ReluFloat/ReluDouble`: ReLUæ¿€æ´»å‡½æ•°
- `SoftmaxFloat/SoftmaxDouble`: Softmaxå‡½æ•°
- `MatMulFloat/MatMulDouble`: çŸ©é˜µä¹˜æ³•

```python
# åˆ›å»ºç®—å­
gemm = cuop.GemmFloat()
gemm.set_weight(weight_tensor)

# æ‰§è¡Œè®¡ç®—
gemm.forward(input_tensor, output_tensor)
```

#### JITåŒ…è£…å™¨

JITä¼˜åŒ–çš„ç®—å­åŒ…è£…å™¨ï¼š

```python
# åˆ›å»ºJITåŒ…è£…å™¨
jit_gemm = cuop.JITGemmFloat(gemm)

# é…ç½®JIT
jit_gemm.enable_jit(True)
jit_gemm.enable_persistent_cache(True)
jit_gemm.set_persistent_cache_directory("./jit_cache")

# è®¾ç½®é…ç½®
config = cuop.JITConfig()
config.kernel_type = "tiled"
config.tile_size = 32
config.block_size = 256
jit_gemm.set_jit_config(config)

# æ‰§è¡Œ
jit_gemm.forward(input_tensor, output_tensor)

# è·å–æ€§èƒ½ä¿¡æ¯
profile = jit_gemm.get_performance_profile()
```

### é…ç½®ç±»

#### JITConfig

JITç¼–è¯‘é…ç½®ï¼š

```python
config = cuop.JITConfig()
config.enable_jit = True
config.kernel_type = "tiled"           # å†…æ ¸ç±»å‹
config.tile_size = 32                  # ç“¦ç‰‡å¤§å°
config.block_size = 256                # å—å¤§å°
config.optimization_level = "O2"       # ä¼˜åŒ–çº§åˆ«
config.enable_tensor_core = True       # å¯ç”¨Tensor Core
config.enable_tma = True               # å¯ç”¨TMA
config.max_registers = 255             # æœ€å¤§å¯„å­˜å™¨æ•°
config.enable_shared_memory_opt = True # å¯ç”¨å…±äº«å†…å­˜ä¼˜åŒ–
config.enable_loop_unroll = True       # å¯ç”¨å¾ªç¯å±•å¼€
config.enable_memory_coalescing = True # å¯ç”¨å†…å­˜åˆå¹¶
```

#### GlobalJITConfig

å…¨å±€JITé…ç½®ï¼š

```python
global_config = cuop.GlobalJITConfig()
global_config.enable_jit = True
global_config.enable_auto_tuning = True
global_config.enable_caching = True
global_config.cache_dir = "./jit_cache"
global_config.max_cache_size = 10 * 1024 * 1024 * 1024  # 10GB
global_config.compilation_timeout = 30
global_config.max_compilation_threads = 4
```

### å·¥å…·å‡½æ•°

#### å¼ é‡åˆ›å»º

```python
# åˆ›å»ºå¼ é‡
tensor = cuop.tensor(numpy_array)
zeros = cuop.zeros(shape)
ones = cuop.ones(shape)
random_tensor = cuop.random(shape, dtype='float32', mean=0.0, std=1.0)

# ç‰¹æ®Šå¼ é‡
identity = cuop.eye(n, dtype='float32')
linspace_tensor = cuop.linspace(start, stop, num, dtype='float32')
logspace_tensor = cuop.logspace(start, stop, num, base=10.0, dtype='float32')
grid_tensors = cuop.meshgrid(*xi, indexing='xy')
```

#### è®¾å¤‡ç®¡ç†

```python
# è®¾å¤‡ä¿¡æ¯
device_count = cuop.get_device_count()
current_device = cuop.get_device()

# è®¾å¤‡æ§åˆ¶
cuop.set_device(device_id)
cuop.synchronize()

# å†…å­˜ä¿¡æ¯
free_mem, total_mem = cuop.get_memory_info()
cuop.empty_cache()
```

#### æ€§èƒ½åˆ†æ

```python
# åŸºå‡†æµ‹è¯•
stats = cuop.benchmark(operator, input_tensor, output_tensor, 
                       num_runs=100, warmup_runs=10)

print(f"å¹³å‡æ—¶é—´: {stats['mean_time_ms']:.3f} ms")
print(f"æ ‡å‡†å·®: {stats['std_time_ms']:.3f} ms")
print(f"æœ€å°æ—¶é—´: {stats['min_time_ms']:.3f} ms")
print(f"æœ€å¤§æ—¶é—´: {stats['max_time_ms']:.3f} ms")
```

## æœ€ä½³å®è·µ

### 1. å†…å­˜ç®¡ç†

```python
# åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„å¼ é‡
del large_tensor
cuop.empty_cache()

# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç®¡ç†å†…å­˜
with cuop.memory_context():
    # åœ¨è¿™ä¸ªä¸Šä¸‹æ–‡ä¸­åˆ›å»ºçš„å¼ é‡ä¼šè‡ªåŠ¨ç®¡ç†
    tensor = cuop.tensor(data)
    # ä½¿ç”¨tensor...
# ç¦»å¼€ä¸Šä¸‹æ–‡åè‡ªåŠ¨æ¸…ç†
```

### 2. JITé…ç½®ä¼˜åŒ–

```python
# æ ¹æ®æ•°æ®å¤§å°é€‰æ‹©é…ç½®
if matrix_size < 1024:
    config.kernel_type = "simple"
    config.tile_size = 16
elif matrix_size < 4096:
    config.kernel_type = "tiled"
    config.tile_size = 32
else:
    config.kernel_type = "tensor_core"
    config.tile_size = 64
```

### 3. æ‰¹é‡å¤„ç†

```python
# ä½¿ç”¨æ‰¹é‡å¤„ç†æé«˜æ•ˆç‡
batch_size = 100
for i in range(0, total_size, batch_size):
    batch = data[i:i+batch_size]
    # å¤„ç†æ‰¹æ¬¡...
    cuop.synchronize()  # å®šæœŸåŒæ­¥
```

### 4. é”™è¯¯å¤„ç†

```python
try:
    result = operator.forward(input, output)
except cuop.MemoryError as e:
    print(f"å†…å­˜ä¸è¶³: {e}")
    cuop.empty_cache()
except cuop.ExecutionError as e:
    print(f"æ‰§è¡Œé”™è¯¯: {e}")
except Exception as e:
    print(f"æœªçŸ¥é”™è¯¯: {e}")
```

## æ€§èƒ½ä¼˜åŒ–

### 1. é€‰æ‹©åˆé€‚çš„ç®—å­

- å°çŸ©é˜µ (< 512x512): ä½¿ç”¨åŸºç¡€ç®—å­
- ä¸­ç­‰çŸ©é˜µ (512x512 - 4096x4096): ä½¿ç”¨JITä¼˜åŒ–ç®—å­
- å¤§çŸ©é˜µ (> 4096x4096): ä½¿ç”¨Tensor Coreä¼˜åŒ–

### 2. å†…å­˜è®¿é—®ä¼˜åŒ–

- ä½¿ç”¨è¿ç»­çš„å†…å­˜å¸ƒå±€
- é¿å…é¢‘ç¹çš„å†…å­˜åˆ†é…/é‡Šæ”¾
- åˆ©ç”¨å…±äº«å†…å­˜ä¼˜åŒ–

### 3. å¹¶è¡ŒåŒ–ç­–ç•¥

- æ ¹æ®GPUæ¶æ„è°ƒæ•´å—å¤§å°
- ä½¿ç”¨é€‚å½“çš„ç“¦ç‰‡å¤§å°
- å¯ç”¨å¾ªç¯å±•å¼€å’Œå‘é‡åŒ–

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAé”™è¯¯**
   ```python
   # æ£€æŸ¥CUDAç¯å¢ƒ
   cuop.print_system_info()
   
   # æ£€æŸ¥è®¾å¤‡çŠ¶æ€
   device_count = cuop.get_device_count()
   current_device = cuop.get_device()
   ```

2. **å†…å­˜ä¸è¶³**
   ```python
   # æ¸…ç†ç¼“å­˜
   cuop.empty_cache()
   
   # æ£€æŸ¥å†…å­˜ä½¿ç”¨
   free_mem, total_mem = cuop.get_memory_info()
   ```

3. **ç¼–è¯‘å¤±è´¥**
   ```python
   # æ£€æŸ¥JITé…ç½®
   config = cuop.get_default_jit_config()
   
   # å°è¯•ä¸åŒçš„ä¼˜åŒ–çº§åˆ«
   config.optimization_level = "O1"  # é™ä½ä¼˜åŒ–çº§åˆ«
   ```

### è°ƒè¯•æ¨¡å¼

```python
# å¯ç”¨è°ƒè¯•æ¨¡å¼
global_config = cuop.get_default_global_jit_config()
global_config.enable_debug = True

# è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
error_msg = operator.get_last_error()
```

## ç¤ºä¾‹ä»£ç 

å®Œæ•´çš„ç¤ºä¾‹ä»£ç è¯·å‚è€ƒï¼š

- `examples/basic_usage.py`: åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹
- `examples/advanced_usage.py`: é«˜çº§åŠŸèƒ½ç¤ºä¾‹

## è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·å‚è€ƒ [CONTRIBUTING.md](../CONTRIBUTING.md) äº†è§£è´¡çŒ®æŒ‡å—ã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ï¼Œè¯¦è§ [LICENSE](../LICENSE) æ–‡ä»¶ã€‚

## æ”¯æŒ

å¦‚æœæ‚¨é‡åˆ°é—®é¢˜æˆ–æœ‰å»ºè®®ï¼Œè¯·ï¼š

1. æŸ¥çœ‹ [æ–‡æ¡£](https://cuop.readthedocs.io/)
2. æœç´¢ [Issues](https://github.com/cuop/cuop/issues)
3. åˆ›å»ºæ–°çš„ [Issue](https://github.com/cuop/cuop/issues/new)
4. åŠ å…¥ [Discussions](https://github.com/cuop/cuop/discussions)

## æ›´æ–°æ—¥å¿—

### v0.1.0
- åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- æ”¯æŒåŸºç¡€CUDAç®—å­
- JITä¼˜åŒ–ç³»ç»Ÿ
- æŒä¹…åŒ–ç¼“å­˜
- Python API 