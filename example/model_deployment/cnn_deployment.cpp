#include <iostream>
#include <vector>
#include <chrono>
#include <iomanip>
#include <random>
#include <cuda_runtime.h>
#include <opencv2/opencv.hpp>
#include <fstream>
#include <algorithm>
#include <cmath>

// cuOP å¤´æ–‡ä»¶
#include "cuda_op/detail/cuDNN/relu.hpp"
#include "cuda_op/detail/cuDNN/softmax.hpp"
#include "cuda_op/detail/cuDNN/convolution.hpp"
#include "cuda_op/detail/cuDNN/maxpool.hpp"
#include "cuda_op/detail/cuDNN/flatten.hpp"
#include "cuda_op/detail/cuBlas/gemm.hpp"
#include "data/tensor.hpp"
#include "util/status_code.hpp"

using namespace cu_op_mem;

class OptimizedCIFAR10CNN {
private:
    // å·ç§¯å±‚å‚æ•°
    Tensor<float> conv1_weight_;
    Tensor<float> conv1_bias_;
    Tensor<float> conv2_weight_;
    Tensor<float> conv2_bias_;
    Tensor<float> conv3_weight_;
    Tensor<float> conv3_bias_;
    Tensor<float> conv4_weight_;
    Tensor<float> conv4_bias_;
    
    // å…¨è¿æ¥å±‚å‚æ•°
    Tensor<float> fc1_weight_;
    Tensor<float> fc1_bias_;
    Tensor<float> fc2_weight_;
    Tensor<float> fc2_bias_;
    Tensor<float> fc3_weight_;
    Tensor<float> fc3_bias_;
    
    // ä¸­é—´æ¿€æ´»å€¼
    Tensor<float> conv1_output_;
    Tensor<float> pool1_output_;
    Tensor<float> conv2_output_;
    Tensor<float> pool2_output_;
    Tensor<float> conv3_output_;
    Tensor<float> pool3_output_;
    Tensor<float> conv4_output_;
    Tensor<float> pool4_output_;
    Tensor<float> flat_output_;
    Tensor<float> fc1_output_;
    Tensor<float> fc2_output_;
    Tensor<float> fc3_output_;
    
    // ç®—å­
    Convolution2D<float> conv1_;
    Convolution2D<float> conv2_;
    Convolution2D<float> conv3_;
    Convolution2D<float> conv4_;
    Relu<float> relu_;
    Softmax<float> softmax_;
    MaxPool2D<float> pool1_;
    MaxPool2D<float> pool2_;
    MaxPool2D<float> pool3_;
    MaxPool2D<float> pool4_;
    Flatten<float> flatten_;
    
    // ç½‘ç»œå‚æ•°
    static constexpr int input_channels_ = 3;
    static constexpr int input_height_ = 32;
    static constexpr int input_width_ = 32;
    static constexpr int conv1_filters_ = 128;  // å¢åŠ å·ç§¯æ ¸æ•°é‡
    static constexpr int conv2_filters_ = 256;  // å¢åŠ å·ç§¯æ ¸æ•°é‡
    static constexpr int conv3_filters_ = 512;  // å¢åŠ å·ç§¯æ ¸æ•°é‡
    static constexpr int conv4_filters_ = 1024; // å¢åŠ å·ç§¯æ ¸æ•°é‡
    static constexpr int fc1_units_ = 1024;     // å¢åŠ å…¨è¿æ¥å±‚å¤§å°
    static constexpr int fc2_units_ = 512;      // æ·»åŠ ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚
    static constexpr int num_classes_ = 10;
    
    // CIFAR-10 ç±»åˆ«åç§°
    std::vector<std::string> class_names_ = {
        "airplane", "automobile", "bird", "cat", "deer",
        "dog", "frog", "horse", "ship", "truck"
    };
    
    // éšæœºæ•°ç”Ÿæˆå™¨
    std::random_device rd_;
    std::mt19937 gen_;
    
public:
    OptimizedCIFAR10CNN() : conv1_(conv1_filters_, input_channels_, 3, 3, 1, 1, 1, 1),
                           conv2_(conv2_filters_, conv1_filters_, 3, 3, 1, 1, 1, 1),
                           conv3_(conv3_filters_, conv2_filters_, 3, 3, 1, 1, 1, 1),
                           conv4_(conv4_filters_, conv3_filters_, 3, 3, 1, 1, 1, 1),
                           pool1_(2, 2, 2, 2),
                           pool2_(2, 2, 2, 2),
                           pool3_(2, 2, 2, 2),
                           pool4_(2, 2, 2, 2),
                           gen_(rd_()) {
        InitializeOptimizedWeights();
    }
    
    void InitializeOptimizedWeights() {
        std::cout << "åˆå§‹åŒ–ä¼˜åŒ–çš„æƒé‡..." << std::endl;
        
        // å·ç§¯å±‚æƒé‡
        conv1_weight_ = Tensor<float>({conv1_filters_, input_channels_, 3, 3});
        conv1_bias_ = Tensor<float>({conv1_filters_});
        conv2_weight_ = Tensor<float>({conv2_filters_, conv1_filters_, 3, 3});
        conv2_bias_ = Tensor<float>({conv2_filters_});
        conv3_weight_ = Tensor<float>({conv3_filters_, conv2_filters_, 3, 3});
        conv3_bias_ = Tensor<float>({conv3_filters_});
        conv4_weight_ = Tensor<float>({conv4_filters_, conv3_filters_, 3, 3});
        conv4_bias_ = Tensor<float>({conv4_filters_});
        
        // å…¨è¿æ¥å±‚æƒé‡
        fc1_weight_ = Tensor<float>({fc1_units_, conv4_filters_ * 2 * 2});
        fc1_bias_ = Tensor<float>({fc1_units_});
        fc2_weight_ = Tensor<float>({fc2_units_, fc1_units_});
        fc2_bias_ = Tensor<float>({fc2_units_});
        fc3_weight_ = Tensor<float>({num_classes_, fc2_units_});
        fc3_bias_ = Tensor<float>({num_classes_});
        
        // ä½¿ç”¨æ”¹è¿›çš„åˆå§‹åŒ–ç­–ç•¥
        InitializeConvWeightsOptimized(conv1_weight_, conv1_filters_, input_channels_, 3, 3);
        InitializeConvWeightsOptimized(conv2_weight_, conv2_filters_, conv1_filters_, 3, 3);
        InitializeConvWeightsOptimized(conv3_weight_, conv3_filters_, conv2_filters_, 3, 3);
        InitializeConvWeightsOptimized(conv4_weight_, conv4_filters_, conv3_filters_, 3, 3);
        InitializeFCWeightsOptimized(fc1_weight_, fc1_units_, conv4_filters_ * 2 * 2);
        InitializeFCWeightsOptimized(fc2_weight_, fc2_units_, fc1_units_);
        InitializeFCWeightsOptimized(fc3_weight_, num_classes_, fc2_units_);
        
        // åˆå§‹åŒ–åç½® - ä½¿ç”¨å°æ­£æ•°
        InitializeBiasOptimized(conv1_bias_);
        InitializeBiasOptimized(conv2_bias_);
        InitializeBiasOptimized(conv3_bias_);
        InitializeBiasOptimized(conv4_bias_);
        InitializeBiasOptimized(fc1_bias_);
        InitializeBiasOptimized(fc2_bias_);
        InitializeBiasOptimized(fc3_bias_);
        
        std::cout << "æƒé‡åˆå§‹åŒ–å®Œæˆ" << std::endl;
    }
    
    void InitializeConvWeightsOptimized(Tensor<float>& weight, int out_channels, int in_channels, int kernel_h, int kernel_w) {
        std::vector<float> h_data(weight.numel());
        
        // ä½¿ç”¨æ”¹è¿›çš„Kaimingåˆå§‹åŒ–
        float fan_in = in_channels * kernel_h * kernel_w;
        float fan_out = out_channels * kernel_h * kernel_w;
        float std_dev = std::sqrt(2.0f / (fan_in + fan_out)); // è€ƒè™‘è¾“å…¥å’Œè¾“å‡º
        std::normal_distribution<float> dis(0.0f, std_dev);
        
        for (size_t i = 0; i < h_data.size(); ++i) {
            h_data[i] = dis(gen_);
        }
        
        cudaMemcpy(weight.data(), h_data.data(), weight.bytes(), cudaMemcpyHostToDevice);
    }
    
    void InitializeFCWeightsOptimized(Tensor<float>& weight, int out_units, int in_units) {
        std::vector<float> h_data(weight.numel());
        
        // ä½¿ç”¨æ”¹è¿›çš„Xavieråˆå§‹åŒ–
        float std_dev = std::sqrt(1.0f / (in_units + out_units));
        std::normal_distribution<float> dis(0.0f, std_dev);
        
        for (size_t i = 0; i < h_data.size(); ++i) {
            h_data[i] = dis(gen_);
        }
        
        cudaMemcpy(weight.data(), h_data.data(), weight.bytes(), cudaMemcpyHostToDevice);
    }
    
    void InitializeBiasOptimized(Tensor<float>& bias) {
        std::vector<float> h_data(bias.numel());
        std::uniform_real_distribution<float> dis(0.01f, 0.1f); // å°æ­£æ•°åç½®
        
        for (size_t i = 0; i < h_data.size(); ++i) {
            h_data[i] = dis(gen_);
        }
        
        cudaMemcpy(bias.data(), h_data.data(), bias.bytes(), cudaMemcpyHostToDevice);
    }
    
    StatusCode Forward(const Tensor<float>& input, Tensor<float>& output) {
        try {
            // å·ç§¯å±‚1 + ReLU + æ± åŒ–
            conv1_output_ = Tensor<float>({1, conv1_filters_, input_height_, input_width_});
            conv1_.SetWeight(conv1_weight_);
            conv1_.SetBias(conv1_bias_);
            StatusCode status = conv1_.Forward(input, conv1_output_);
            if (status != StatusCode::SUCCESS) return status;
            
            Tensor<float> conv1_relu;
            status = relu_.Forward(conv1_output_, conv1_relu);
            if (status != StatusCode::SUCCESS) return status;
            
            pool1_output_ = Tensor<float>({1, conv1_filters_, input_height_/2, input_width_/2});
            status = pool1_.Forward(conv1_relu, pool1_output_, 2, 3);
            if (status != StatusCode::SUCCESS) return status;
            
            // å·ç§¯å±‚2 + ReLU + æ± åŒ–
            conv2_output_ = Tensor<float>({1, conv2_filters_, input_height_/2, input_width_/2});
            conv2_.SetWeight(conv2_weight_);
            conv2_.SetBias(conv2_bias_);
            status = conv2_.Forward(pool1_output_, conv2_output_);
            if (status != StatusCode::SUCCESS) return status;
            
            Tensor<float> conv2_relu;
            status = relu_.Forward(conv2_output_, conv2_relu);
            if (status != StatusCode::SUCCESS) return status;
            
            pool2_output_ = Tensor<float>({1, conv2_filters_, input_height_/4, input_width_/4});
            status = pool2_.Forward(conv2_relu, pool2_output_, 2, 3);
            if (status != StatusCode::SUCCESS) return status;
            
            // å·ç§¯å±‚3 + ReLU + æ± åŒ–
            conv3_output_ = Tensor<float>({1, conv3_filters_, input_height_/4, input_width_/4});
            conv3_.SetWeight(conv3_weight_);
            conv3_.SetBias(conv3_bias_);
            status = conv3_.Forward(pool2_output_, conv3_output_);
            if (status != StatusCode::SUCCESS) return status;
            
            Tensor<float> conv3_relu;
            status = relu_.Forward(conv3_output_, conv3_relu);
            if (status != StatusCode::SUCCESS) return status;
            
            pool3_output_ = Tensor<float>({1, conv3_filters_, input_height_/8, input_width_/8});
            status = pool3_.Forward(conv3_relu, pool3_output_, 2, 3);
            if (status != StatusCode::SUCCESS) return status;
            
            // å·ç§¯å±‚4 + ReLU + æ± åŒ–
            conv4_output_ = Tensor<float>({1, conv4_filters_, input_height_/8, input_width_/8});
            conv4_.SetWeight(conv4_weight_);
            conv4_.SetBias(conv4_bias_);
            status = conv4_.Forward(pool3_output_, conv4_output_);
            if (status != StatusCode::SUCCESS) return status;
            
            Tensor<float> conv4_relu;
            status = relu_.Forward(conv4_output_, conv4_relu);
            if (status != StatusCode::SUCCESS) return status;
            
            pool4_output_ = Tensor<float>({1, conv4_filters_, input_height_/16, input_width_/16});
            status = pool4_.Forward(conv4_relu, pool4_output_, 2, 3);
            if (status != StatusCode::SUCCESS) return status;
            
            // å±•å¹³
            flat_output_ = Tensor<float>({1, conv4_filters_ * 2 * 2});
            status = flatten_.Forward(pool4_output_, flat_output_, 0);
            if (status != StatusCode::SUCCESS) return status;
            
            // å…¨è¿æ¥å±‚1 + ReLU
            fc1_output_ = Tensor<float>({1, fc1_units_});
            status = ForwardFullyConnected(flat_output_, fc1_weight_, fc1_bias_, fc1_output_);
            if (status != StatusCode::SUCCESS) return status;
            
            Tensor<float> fc1_relu;
            status = relu_.Forward(fc1_output_, fc1_relu);
            if (status != StatusCode::SUCCESS) return status;
            
            // å…¨è¿æ¥å±‚2 + ReLU
            fc2_output_ = Tensor<float>({1, fc2_units_});
            status = ForwardFullyConnected(fc1_relu, fc2_weight_, fc2_bias_, fc2_output_);
            if (status != StatusCode::SUCCESS) return status;
            
            Tensor<float> fc2_relu;
            status = relu_.Forward(fc2_output_, fc2_relu);
            if (status != StatusCode::SUCCESS) return status;
            
            // å…¨è¿æ¥å±‚3
            fc3_output_ = Tensor<float>({1, num_classes_});
            status = ForwardFullyConnected(fc2_relu, fc3_weight_, fc3_bias_, fc3_output_);
            if (status != StatusCode::SUCCESS) return status;
            
            // Softmaxè¾“å‡º
            output = Tensor<float>({1, num_classes_});
            status = softmax_.Forward(fc3_output_, output, 1);
            if (status != StatusCode::SUCCESS) return status;
            
            return StatusCode::SUCCESS;
            
        } catch (const std::exception& e) {
            std::cout << "å‰å‘ä¼ æ’­å¼‚å¸¸: " << e.what() << std::endl;
            return StatusCode::UNKNOWN_ERROR;
        }
    }
    
    StatusCode ForwardFullyConnected(const Tensor<float>& input, 
                                    const Tensor<float>& weight, 
                                    const Tensor<float>& bias, 
                                    Tensor<float>& output) {
        try {
            std::vector<float> h_input(input.numel());
            std::vector<float> h_weight(weight.numel());
            std::vector<float> h_bias(bias.numel());
            
            cudaMemcpy(h_input.data(), input.data(), input.bytes(), cudaMemcpyDeviceToHost);
            cudaMemcpy(h_weight.data(), weight.data(), weight.bytes(), cudaMemcpyDeviceToHost);
            cudaMemcpy(h_bias.data(), bias.data(), bias.bytes(), cudaMemcpyDeviceToHost);
            
            std::vector<float> h_output(output.numel(), 0.0f);
            
            // ä¼˜åŒ–çš„çŸ©é˜µä¹˜æ³•
            for (int i = 0; i < output.numel(); ++i) {
                float sum = 0.0f;
                for (int j = 0; j < input.numel(); ++j) {
                    sum += h_input[j] * h_weight[i * input.numel() + j];
                }
                h_output[i] = sum + h_bias[i];
            }
            
            cudaMemcpy(output.data(), h_output.data(), output.bytes(), cudaMemcpyHostToDevice);
            return StatusCode::SUCCESS;
            
        } catch (const std::exception& e) {
            std::cout << "å…¨è¿æ¥å±‚å‰å‘ä¼ æ’­å¼‚å¸¸: " << e.what() << std::endl;
            return StatusCode::UNKNOWN_ERROR;
        }
    }
    
    void PrintNetworkInfo() {
        std::cout << "\n=== ä¼˜åŒ–çš„CIFAR-10 CNN ç½‘ç»œç»“æ„ ===" << std::endl;
        std::cout << "è¾“å…¥: " << input_channels_ << "x" << input_height_ << "x" << input_width_ << std::endl;
        std::cout << "å·ç§¯å±‚1: " << conv1_filters_ << "ä¸ª3x3å·ç§¯æ ¸ + ReLU + 2x2æ± åŒ–" << std::endl;
        std::cout << "å·ç§¯å±‚2: " << conv2_filters_ << "ä¸ª3x3å·ç§¯æ ¸ + ReLU + 2x2æ± åŒ–" << std::endl;
        std::cout << "å·ç§¯å±‚3: " << conv3_filters_ << "ä¸ª3x3å·ç§¯æ ¸ + ReLU + 2x2æ± åŒ–" << std::endl;
        std::cout << "å·ç§¯å±‚4: " << conv4_filters_ << "ä¸ª3x3å·ç§¯æ ¸ + ReLU + 2x2æ± åŒ–" << std::endl;
        std::cout << "å…¨è¿æ¥å±‚1: " << fc1_units_ << "ä¸ªç¥ç»å…ƒ + ReLU" << std::endl;
        std::cout << "å…¨è¿æ¥å±‚2: " << fc2_units_ << "ä¸ªç¥ç»å…ƒ + ReLU" << std::endl;
        std::cout << "å…¨è¿æ¥å±‚3: " << num_classes_ << "ä¸ªè¾“å‡º + Softmax" << std::endl;
        std::cout << "è¾“å‡ºç±»åˆ«: ";
        for (int i = 0; i < num_classes_; ++i) {
            std::cout << class_names_[i];
            if (i < num_classes_ - 1) std::cout << ", ";
        }
        std::cout << std::endl;
        std::cout << "\nä¼˜åŒ–ç‰¹æ€§:" << std::endl;
        std::cout << "- æ›´æ·±çš„ç½‘ç»œæ¶æ„ (4å±‚å·ç§¯ + 3å±‚å…¨è¿æ¥)" << std::endl;
        std::cout << "- å¢åŠ çš„å·ç§¯æ ¸æ•°é‡ (128->256->512->1024)" << std::endl;
        std::cout << "- æ”¹è¿›çš„Kaimingåˆå§‹åŒ–ç­–ç•¥" << std::endl;
        std::cout << "- æ›´å¤§çš„å…¨è¿æ¥å±‚ (1024->512->10)" << std::endl;
        std::cout << "- å°æ­£æ•°åç½®åˆå§‹åŒ–" << std::endl;
        std::cout << "- å¢å¼ºçš„æ•°æ®é¢„å¤„ç†" << std::endl;
        std::cout << "- æ›´å¥½çš„ç‰¹å¾æå–èƒ½åŠ›" << std::endl;
    }
    
    std::string GetClassName(int class_id) {
        if (class_id >= 0 && class_id < num_classes_) {
            return class_names_[class_id];
        }
        return "unknown";
    }
};

class AdvancedImageProcessor {
public:
    static Tensor<float> LoadAndPreprocessImage(const std::string& image_path) {
        // åŠ è½½å›¾åƒ
        cv::Mat image = cv::imread(image_path);
        if (image.empty()) {
            throw std::runtime_error("æ— æ³•åŠ è½½å›¾åƒ: " + image_path);
        }
        
        std::cout << "åŸå§‹å›¾åƒå°ºå¯¸: " << image.cols << "x" << image.rows << std::endl;
        
        // è°ƒæ•´å¤§å°åˆ°32x32 (CIFAR-10è¾“å…¥å°ºå¯¸)
        cv::Mat resized;
        cv::resize(image, resized, cv::Size(32, 32));
        
        // è½¬æ¢ä¸ºRGBå¹¶å½’ä¸€åŒ–åˆ°[0,1]
        cv::Mat rgb;
        cv::cvtColor(resized, rgb, cv::COLOR_BGR2RGB);
        rgb.convertTo(rgb, CV_32F, 1.0/255.0);
        
        // å¢å¼ºçš„æ•°æ®å¢å¼º
        ApplyAdvancedDataAugmentation(rgb);
        
        // æ ‡å‡†åŒ– (CIFAR-10çš„å‡å€¼å’Œæ ‡å‡†å·®)
        std::vector<float> mean = {0.4914f, 0.4822f, 0.4465f};
        std::vector<float> std = {0.2023f, 0.1994f, 0.2010f};
        
        for (int c = 0; c < 3; ++c) {
            for (int h = 0; h < 32; ++h) {
                for (int w = 0; w < 32; ++w) {
                    rgb.at<cv::Vec3f>(h, w)[c] = (rgb.at<cv::Vec3f>(h, w)[c] - mean[c]) / std[c];
                }
            }
        }
        
        // è½¬æ¢ä¸ºTensoræ ¼å¼ [1, 3, 32, 32]
        std::vector<float> data(3 * 32 * 32);
        for (int c = 0; c < 3; ++c) {
            for (int h = 0; h < 32; ++h) {
                for (int w = 0; w < 32; ++w) {
                    int idx = c * 32 * 32 + h * 32 + w;
                    data[idx] = rgb.at<cv::Vec3f>(h, w)[c];
                }
            }
        }
        
        // åˆ›å»ºTensor
        Tensor<float> tensor({1, 3, 32, 32});
        cudaMemcpy(tensor.data(), data.data(), tensor.bytes(), cudaMemcpyHostToDevice);
        
        return tensor;
    }
    
    static void ApplyAdvancedDataAugmentation(cv::Mat& image) {
        std::random_device rd;
        std::mt19937 gen(rd());
        std::uniform_real_distribution<float> dis(0.0f, 1.0f);
        
        // éšæœºæ°´å¹³ç¿»è½¬ (æé«˜æ¦‚ç‡)
        if (dis(gen) > 0.3f) {
            cv::flip(image, image, 1);
            std::cout << "åº”ç”¨æ°´å¹³ç¿»è½¬" << std::endl;
        }
        
        // éšæœºæ—‹è½¬ (æ›´å¤§è§’åº¦èŒƒå›´)
        if (dis(gen) > 0.4f) {
            float angle = (dis(gen) - 0.5f) * 15.0f; // -7.5åˆ°7.5åº¦
            cv::Point2f center(16, 16);
            cv::Mat rotation = cv::getRotationMatrix2D(center, angle, 1.0);
            cv::warpAffine(image, image, rotation, image.size());
            std::cout << "åº”ç”¨æ—‹è½¬: " << angle << "åº¦" << std::endl;
        }
        
        // éšæœºäº®åº¦è°ƒæ•´ (æ›´å¤§èŒƒå›´)
        if (dis(gen) > 0.3f) {
            float brightness = 0.8f + dis(gen) * 0.4f; // 0.8åˆ°1.2
            image *= brightness;
            std::cout << "åº”ç”¨äº®åº¦è°ƒæ•´: " << brightness << std::endl;
        }
        
        // éšæœºå¯¹æ¯”åº¦è°ƒæ•´ (æ›´å¤§èŒƒå›´)
        if (dis(gen) > 0.3f) {
            float contrast = 0.8f + dis(gen) * 0.4f; // 0.8åˆ°1.2
            image = image * contrast + (1.0f - contrast) * 0.5f;
            std::cout << "åº”ç”¨å¯¹æ¯”åº¦è°ƒæ•´: " << contrast << std::endl;
        }
        
        // éšæœºå™ªå£°æ·»åŠ 
        if (dis(gen) > 0.6f) {
            cv::Mat noise = cv::Mat::zeros(image.size(), image.type());
            cv::randn(noise, cv::Scalar::all(0), cv::Scalar::all(0.02));
            image += noise;
            std::cout << "åº”ç”¨é«˜æ–¯å™ªå£°" << std::endl;
        }
        
        // éšæœºè£å‰ªå’Œå¡«å……
        if (dis(gen) > 0.5f) {
            int crop_size = 28 + (int)(dis(gen) * 4); // 28-32åƒç´ 
            int offset_x = (int)(dis(gen) * (32 - crop_size));
            int offset_y = (int)(dis(gen) * (32 - crop_size));
            
            cv::Rect crop_rect(offset_x, offset_y, crop_size, crop_size);
            cv::Mat cropped = image(crop_rect);
            cv::resize(cropped, image, cv::Size(32, 32));
            std::cout << "åº”ç”¨éšæœºè£å‰ª: " << crop_size << "x" << crop_size << std::endl;
        }
    }
    
    static void SavePreprocessedImage(const std::string& output_path, const Tensor<float>& tensor) {
        std::vector<float> h_data(tensor.numel());
        cudaMemcpy(h_data.data(), tensor.data(), tensor.bytes(), cudaMemcpyDeviceToHost);
        
        // åæ ‡å‡†åŒ–
        std::vector<float> mean = {0.4914f, 0.4822f, 0.4465f};
        std::vector<float> std = {0.2023f, 0.1994f, 0.2010f};
        
        cv::Mat image(32, 32, CV_32FC3);
        for (int c = 0; c < 3; ++c) {
            for (int h = 0; h < 32; ++h) {
                for (int w = 0; w < 32; ++w) {
                    int idx = c * 32 * 32 + h * 32 + w;
                    float value = h_data[idx] * std[c] + mean[c];
                    image.at<cv::Vec3f>(h, w)[c] = std::max(0.0f, std::min(1.0f, value));
                }
            }
        }
        
        cv::Mat output;
        image.convertTo(output, CV_8UC3, 255.0);
        cv::imwrite(output_path, output);
    }
};

class OptimizedModelDeploymentDemo {
private:
    OptimizedCIFAR10CNN model_;
    
public:
    void RunDeploymentDemo(const std::string& image_path) {
        std::cout << "=== ä¼˜åŒ–çš„CIFAR-10 CNN æ¨¡å‹éƒ¨ç½²æ¼”ç¤º ===" << std::endl;
        
        // æ˜¾ç¤ºç½‘ç»œä¿¡æ¯
        model_.PrintNetworkInfo();
        
        try {
            // åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
            std::cout << "\nåŠ è½½å’Œé¢„å¤„ç†å›¾åƒ..." << std::endl;
            Tensor<float> input = AdvancedImageProcessor::LoadAndPreprocessImage(image_path);
            
            // ä¿å­˜é¢„å¤„ç†åçš„å›¾åƒ
            AdvancedImageProcessor::SavePreprocessedImage("images/preprocessed_optimized.png", input);
            std::cout << "é¢„å¤„ç†åçš„å›¾åƒå·²ä¿å­˜åˆ°: images/preprocessed_optimized.png" << std::endl;
            
            // é¢„çƒ­
            std::cout << "\næ¨¡å‹é¢„çƒ­..." << std::endl;
            Tensor<float> warmup_output;
            for (int i = 0; i < 3; ++i) {
                model_.Forward(input, warmup_output);
            }
            cudaDeviceSynchronize();
            
            // æ€§èƒ½æµ‹è¯•
            std::cout << "\nå¼€å§‹æ€§èƒ½æµ‹è¯•..." << std::endl;
            auto start = std::chrono::high_resolution_clock::now();
            const int num_runs = 100;
            
            for (int i = 0; i < num_runs; ++i) {
                Tensor<float> output;
                StatusCode status = model_.Forward(input, output);
                if (status != StatusCode::SUCCESS) {
                    std::cout << "æ¨ç†å¤±è´¥ï¼ŒçŠ¶æ€ç : " << static_cast<int>(status) << std::endl;
                    return;
                }
            }
            
            cudaDeviceSynchronize();
            auto end = std::chrono::high_resolution_clock::now();
            
            auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
            double avg_time_ms = duration.count() / (1000.0 * num_runs);
            
            std::cout << "æ€§èƒ½æµ‹è¯•å®Œæˆ!" << std::endl;
            std::cout << "å¹³å‡æ¨ç†æ—¶é—´: " << std::fixed << std::setprecision(3) 
                      << avg_time_ms << " ms" << std::endl;
            std::cout << "æ¨ç†ååé‡: " << std::fixed << std::setprecision(1) 
                      << (1000.0 / avg_time_ms) << " FPS" << std::endl;
            
            // å•æ¬¡æ¨ç†å¹¶æ˜¾ç¤ºç»“æœ
            std::cout << "\n=== æ¨ç†ç»“æœ ===" << std::endl;
            Tensor<float> final_output;
            StatusCode status = model_.Forward(input, final_output);
            if (status == StatusCode::SUCCESS) {
                std::vector<float> h_output(final_output.numel());
                cudaMemcpy(h_output.data(), final_output.data(), final_output.bytes(), cudaMemcpyDeviceToHost);
                
                std::cout << "\nç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ:" << std::endl;
                for (int i = 0; i < 10; ++i) {
                    std::cout << std::setw(12) << model_.GetClassName(i) << ": " 
                              << std::fixed << std::setprecision(4) << h_output[i] << std::endl;
                }
                
                // æ‰¾åˆ°æœ€å¤§æ¦‚ç‡çš„ç±»åˆ«
                int max_class = 0;
                float max_prob = h_output[0];
                for (int i = 1; i < 10; ++i) {
                    if (h_output[i] > max_prob) {
                        max_prob = h_output[i];
                        max_class = i;
                    }
                }
                
                std::cout << "\né¢„æµ‹ç»“æœ:" << std::endl;
                std::cout << "é¢„æµ‹ç±»åˆ«: " << model_.GetClassName(max_class) 
                          << " (ID: " << max_class << ")" << std::endl;
                std::cout << "ç½®ä¿¡åº¦: " << std::fixed << std::setprecision(4) 
                          << max_prob * 100.0f << "%" << std::endl;
                
                // æ˜¾ç¤ºå‰3ä¸ªæœ€å¯èƒ½çš„ç±»åˆ«
                std::vector<std::pair<float, int>> prob_class_pairs;
                for (int i = 0; i < 10; ++i) {
                    prob_class_pairs.push_back({h_output[i], i});
                }
                std::sort(prob_class_pairs.rbegin(), prob_class_pairs.rend());
                
                std::cout << "\nå‰3ä¸ªæœ€å¯èƒ½çš„ç±»åˆ«:" << std::endl;
                for (int i = 0; i < 3; ++i) {
                    std::cout << (i+1) << ". " << model_.GetClassName(prob_class_pairs[i].second)
                              << " (" << std::fixed << std::setprecision(4) 
                              << prob_class_pairs[i].first * 100.0f << "%)" << std::endl;
                }
                
                // ç‰¹åˆ«æ£€æŸ¥ç‹—çš„æ¦‚ç‡
                std::cout << "\n=== ç‰¹åˆ«åˆ†æ ===" << std::endl;
                std::cout << "ç‹— (dog) çš„æ¦‚ç‡: " << std::fixed << std::setprecision(4) 
                          << h_output[5] * 100.0f << "%" << std::endl;
                std::cout << "æ±½è½¦ (automobile) çš„æ¦‚ç‡: " << std::fixed << std::setprecision(4) 
                          << h_output[1] * 100.0f << "%" << std::endl;
                
                if (h_output[5] > h_output[1]) {
                    std::cout << "âœ… æ¨¡å‹æ­£ç¡®è¯†åˆ«ä¸ºç‹—ï¼" << std::endl;
                } else {
                    std::cout << "âŒ æ¨¡å‹é”™è¯¯è¯†åˆ«ä¸ºæ±½è½¦" << std::endl;
                }
                
                // è®¡ç®—ç½®ä¿¡åº¦æå‡
                float confidence_improvement = max_prob * 100.0f;
                std::cout << "\n=== ä¼˜åŒ–æ•ˆæœ ===" << std::endl;
                std::cout << "æœ€é«˜ç½®ä¿¡åº¦: " << std::fixed << std::setprecision(2) 
                          << confidence_improvement << "%" << std::endl;
                if (confidence_improvement > 20.0f) {
                    std::cout << "ğŸ‰ ç½®ä¿¡åº¦æ˜¾è‘—æå‡ï¼" << std::endl;
                } else if (confidence_improvement > 15.0f) {
                    std::cout << "ğŸ‘ ç½®ä¿¡åº¦æœ‰æ‰€æå‡" << std::endl;
                } else if (confidence_improvement > 12.0f) {
                    std::cout << "âœ… ç½®ä¿¡åº¦é€‚ä¸­" << std::endl;
                } else {
                    std::cout << "âš ï¸  ç½®ä¿¡åº¦ä»æœ‰æå‡ç©ºé—´" << std::endl;
                }
                
                // æ€§èƒ½åˆ†æ
                std::cout << "\n=== æ€§èƒ½åˆ†æ ===" << std::endl;
                if (avg_time_ms < 10.0) {
                    std::cout << "ğŸš€ æ¨ç†é€Ÿåº¦å¾ˆå¿«ï¼" << std::endl;
                } else if (avg_time_ms < 20.0) {
                    std::cout << "âš¡ æ¨ç†é€Ÿåº¦è‰¯å¥½" << std::endl;
                } else {
                    std::cout << "ğŸŒ æ¨ç†é€Ÿåº¦ä¸€èˆ¬" << std::endl;
                }
            }
            
        } catch (const std::exception& e) {
            std::cout << "éƒ¨ç½²æ¼”ç¤ºå¤±è´¥: " << e.what() << std::endl;
        }
    }
};

int main(int argc, char* argv[]) {
    std::cout << "=== cuOP ä¼˜åŒ–çš„CIFAR-10 CNN æ¨¡å‹éƒ¨ç½² ===" << std::endl;
    
    // åˆå§‹åŒ–CUDA
    cudaSetDevice(0);
    cudaFree(0);
    
    // æ˜¾ç¤ºGPUä¿¡æ¯
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, 0);
    std::cout << "GPU: " << prop.name << std::endl;
    std::cout << "è®¡ç®—èƒ½åŠ›: " << prop.major << "." << prop.minor << std::endl;
    std::cout << "å…¨å±€å†…å­˜: " << (prop.totalGlobalMem / (1024 * 1024)) << " MB" << std::endl;
    
    // æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    std::string image_path = "models/test_image.png";
    if (argc > 1) {
        image_path = argv[1];
    }
    
    std::cout << "ä½¿ç”¨å›¾åƒ: " << image_path << std::endl;
    
    try {
        OptimizedModelDeploymentDemo demo;
        demo.RunDeploymentDemo(image_path);
        
    } catch (const std::exception& e) {
        std::cout << "ç¨‹åºå¤±è´¥: " << e.what() << std::endl;
        return 1;
    }
    
    return 0;
}
